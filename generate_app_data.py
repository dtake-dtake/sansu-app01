# generate_app_data.py (æ”¹è‰¯ç‰ˆ)
# -----------------------------------------------------------------------------
# æ¦‚è¦:
#   updates_list.tsv ã‹ã‚‰ã€Œå˜å…ƒåã€ã‚’èª­ã¿è¾¼ã¿ã€
#   å®Ÿéš›ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã¨ç…§ã‚‰ã—åˆã‚ã›ãªãŒã‚‰ app_data.json ã‚’å…¨è‡ªå‹•ã§ç”Ÿæˆã—ã¾ã™ã€‚
#
# ä½¿ã„æ–¹:
#   1. å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:
#      pip install beautifulsoup4
#   2. ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™:
#      python generate_app_data.py
# -----------------------------------------------------------------------------

import os
import json
import re
import shutil
import csv
from datetime import datetime
from collections import defaultdict

try:
    from bs4 import BeautifulSoup
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: beautifulsoup4 ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    print("ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ pip install beautifulsoup4 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    exit()

# --- è¨­å®šé …ç›® ---
# ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ã®å­¦å¹´ãƒ•ã‚©ãƒ«ãƒ€
TARGET_DIRECTORIES = ["1nen", "2nen", "3nen", "4nen", "5nen", "6nen", "common"]
# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
OUTPUT_JSON_FILE = "app_data.json"
# å˜å…ƒåã®å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«
UNIT_LIST_TSV = "updates_list.tsv"
# --- è¨­å®šã“ã“ã¾ã§ ---

def load_unit_names(tsv_file):
    """updates_list.tsvã‚’èª­ã¿è¾¼ã¿ã€ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã¨å˜å…ƒåã®å¯¾å¿œè¾æ›¸ã‚’ä½œæˆã™ã‚‹"""
    unit_map = {}
    if not os.path.exists(tsv_file):
        print(f"è­¦å‘Š: {tsv_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ«ãƒ€åã‚’å˜å…ƒåã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
        return unit_map

    try:
        with open(tsv_file, "r", encoding="utf-8") as f:
            # tsvãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¿ãƒ–åŒºåˆ‡ã‚Šãªã®ã§ã€csvãƒªãƒ¼ãƒ€ãƒ¼ã§æ–¹è¨€ã‚’æŒ‡å®šã—ã¦èª­ã¿è¾¼ã‚€
            reader = csv.reader(f, delimiter='\t')
            for row in reader:
                if len(row) >= 2:
                    # 1åˆ—ç›®: ãƒ‘ã‚¹ (ä¾‹: 1nen/06_tashizan1/9-3_tashizan_10made.html)
                    # 2åˆ—ç›®: å˜å…ƒå (ä¾‹: ãŸã—ã–ã‚“(1))
                    path = row[0].strip().replace("\\", "/")
                    unit_name = row[1].strip()
                    # ãƒ‘ã‚¹ã‹ã‚‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªéƒ¨åˆ†ã ã‘ã‚’æŠ½å‡º
                    unit_dir = os.path.dirname(path)
                    if unit_dir and unit_dir not in unit_map:
                        unit_map[unit_dir] = unit_name
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {tsv_file} ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    return unit_map

def extract_app_info(file_path):
    """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¢ãƒ—ãƒªåã¨appIdã‚’æŠ½å‡ºã™ã‚‹"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception:
        try:
            with open(file_path, "r", encoding="shift_jis") as f:
                content = f.read()
        except Exception as e:
            print(f"è­¦å‘Š: ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {file_path} ({e})")
            return None, None

    app_id_match = re.search(r'appId\s*=\s*["\'](.*?)["\']', content)
    app_id = app_id_match.group(1) if app_id_match else None
    soup = BeautifulSoup(content, 'html.parser')
    app_name = soup.title.string.strip() if soup.title else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"

    if not app_id:
        print(f"è­¦å‘Š: appIdãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {file_path}")
        return None, None

    return app_name, app_id

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ã‚¢ãƒ—ãƒªã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
    # ã¾ãšå˜å…ƒåã®å¯¾å¿œãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
    unit_name_map = load_unit_names(UNIT_LIST_TSV)
    all_grades_data = []

    for grade_name in TARGET_DIRECTORIES:
        grade_path = grade_name
        if not os.path.isdir(grade_path):
            continue

        print(f"ã€{grade_name}ã€‘ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†ä¸­...")
        units = defaultdict(list)

        for dirpath, _, filenames in os.walk(grade_path):
            for filename in [f for f in filenames if f.lower().endswith('.html')]:
                file_path = os.path.join(dirpath, filename).replace("\\", "/")
                app_name, app_id = extract_app_info(file_path)

                if app_name and app_id:
                    unit_path = os.path.dirname(file_path)
                    app_data = {
                        "name": app_name,
                        "path": file_path,
                        "appId": app_id
                    }
                    units[unit_path].append(app_data)

        if not units:
            continue

        grade_units_list = []
        for unit_path in sorted(units.keys()):
            # tsvãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å˜å…ƒåã‚’å–å¾—ã€‚ãªã‘ã‚Œã°ãƒ•ã‚©ãƒ«ãƒ€åã‚’å˜å…ƒåã¨ã™ã‚‹
            unit_name = unit_name_map.get(unit_path, os.path.basename(unit_path))
            grade_units_list.append({
                "name": unit_name,
                "apps": sorted(units[unit_path], key=lambda x: x['path'])
            })

        all_grades_data.append({
            "grade": grade_name,
            "units": grade_units_list
        })

    if os.path.exists(OUTPUT_JSON_FILE):
        backup_filename = f"{OUTPUT_JSON_FILE}.{datetime.now().strftime('%Y%m%d_%H%M%S')}.bak"
        shutil.copyfile(OUTPUT_JSON_FILE, backup_filename)
        print(f"æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: {backup_filename}")

    with open(OUTPUT_JSON_FILE, "w", encoding="utf-8") as f:
        json.dump(all_grades_data, f, ensure_ascii=False, indent=2)

    print("-" * 40)
    print(f"ğŸ‰ {OUTPUT_JSON_FILE} ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ ({len(all_grades_data)}å­¦å¹´åˆ†)")
    print("-" * 40)

if __name__ == "__main__":
    main()